# LLM-Judgment-Bender
Are LLM-judges robust to adversarial inputs?

This repository contains my solution for the **LLM-as-a-Judge Exploit Detection** competition. The goal of this project is to identify methods to exploit LLM-based systems designed to evaluate the quality of essays. By submitting essays that maximize disagreement between LLM judges, this project contributes to the understanding of the vulnerabilities and limitations of such systems.

